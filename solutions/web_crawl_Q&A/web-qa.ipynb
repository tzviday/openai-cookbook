{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openai.com/\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 138\u001b[0m\n\u001b[0;32m    135\u001b[0m                 queue\u001b[39m.\u001b[39mappend(link)\n\u001b[0;32m    136\u001b[0m                 seen\u001b[39m.\u001b[39madd(link)\n\u001b[1;32m--> 138\u001b[0m crawl(full_url)\n",
      "Cell \u001b[1;32mIn[27], line 128\u001b[0m, in \u001b[0;36mcrawl\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUnable to parse page \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m url \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m due to JavaScript being required\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    127\u001b[0m     \u001b[39m# Otherwise, write the text to the file in the text directory\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     f\u001b[39m.\u001b[39;49mwrite(text\u001b[39m.\u001b[39;49mencode(\u001b[39m'\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m'\u001b[39;49m, errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m    132\u001b[0m \u001b[39m# Get the hyperlinks from the URL and add them to the queue\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m get_domain_hyperlinks(local_domain, url):\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "from html.parser import HTMLParser\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "\n",
    "# Regex pattern to match a URL\n",
    "HTTP_URL_PATTERN = r'^http[s]*://.+'\n",
    "\n",
    "# Define root domain to crawl\n",
    "domain = \"openai.com\"\n",
    "full_url = \"https://openai.com/\"\n",
    "\n",
    "# Create a class to parse the HTML and get the hyperlinks\n",
    "class HyperlinkParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Create a list to store the hyperlinks\n",
    "        self.hyperlinks = []\n",
    "\n",
    "    # Override the HTMLParser's handle_starttag method to get the hyperlinks\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        attrs = dict(attrs)\n",
    "\n",
    "        # If the tag is an anchor tag and it has an href attribute, add the href attribute to the list of hyperlinks\n",
    "        if tag == \"a\" and \"href\" in attrs:\n",
    "            self.hyperlinks.append(attrs[\"href\"])\n",
    "\n",
    "# Function to get the hyperlinks from a URL\n",
    "def get_hyperlinks(url):\n",
    "    \n",
    "    # Try to open the URL and read the HTML\n",
    "    try:\n",
    "        # Open the URL and read the HTML\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "\n",
    "            # If the response is not HTML, return an empty list\n",
    "            if not response.info().get('Content-Type').startswith(\"text/html\"):\n",
    "                return []\n",
    "            \n",
    "            # Decode the HTML\n",
    "            html = response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "    # Create the HTML Parser and then Parse the HTML to get hyperlinks\n",
    "    parser = HyperlinkParser()\n",
    "    parser.feed(html)\n",
    "\n",
    "    return parser.hyperlinks\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    for link in set(get_hyperlinks(url)):\n",
    "        clean_link = None\n",
    "\n",
    "        # If the link is a URL, check if it is within the same domain\n",
    "        if re.search(HTTP_URL_PATTERN, link):\n",
    "            # Parse the URL and check if the domain is the same\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain:\n",
    "                clean_link = link\n",
    "\n",
    "        # If the link is not a URL, check if it is a relative link\n",
    "        else:\n",
    "            if link.startswith(\"/\"):\n",
    "                link = link[1:]\n",
    "            elif link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
    "                continue\n",
    "            clean_link = \"https://\" + local_domain + \"/\" + link\n",
    "\n",
    "        if clean_link is not None:\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    # Return the list of hyperlinks that are within the same domain\n",
    "    return list(set(clean_links))\n",
    "\n",
    "\n",
    "def crawl(url):\n",
    "    # Parse the URL and get the domain\n",
    "    local_domain = urlparse(url).netloc\n",
    "\n",
    "    # Create a queue to store the URLs to crawl\n",
    "    queue = deque([url])\n",
    "\n",
    "    # Create a set to store the URLs that have already been seen (no duplicates)\n",
    "    seen = set([url])\n",
    "\n",
    "    # Create a directory to store the text files\n",
    "    if not os.path.exists(\"text/\"):\n",
    "            os.mkdir(\"text/\")\n",
    "\n",
    "    if not os.path.exists(\"text/\"+local_domain+\"/\"):\n",
    "            os.mkdir(\"text/\" + local_domain + \"/\")\n",
    "\n",
    "    # Create a directory to store the csv files\n",
    "    if not os.path.exists(\"processed\"):\n",
    "            os.mkdir(\"processed\")\n",
    "\n",
    "    # While the queue is not empty, continue crawling\n",
    "    while queue:\n",
    "\n",
    "        # Get the next URL from the queue\n",
    "        url = queue.pop()\n",
    "        print(url) # for debugging and to see the progress\n",
    "\n",
    "        # Save text from the url to a <url>.txt file\n",
    "        with open('text/'+local_domain+'/'+url[8:].replace(\"/\", \"_\") + \".txt\", \"w\") as f:\n",
    "\n",
    "            # Get the text from the URL using BeautifulSoup\n",
    "            soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "            # Get the text but remove the tags\n",
    "            text = soup.get_text()\n",
    "\n",
    "            # If the crawler gets to a page that requires JavaScript, it will stop the crawl\n",
    "            if (\"You need to enable JavaScript to run this app.\" in text):\n",
    "                print(\"Unable to parse page \" + url + \" due to JavaScript being required\")\n",
    "            \n",
    "            # Otherwise, write the text to the file in the text directory\n",
    "            f.write(text.encode('utf-8', errors='replace'))\n",
    "\n",
    "\n",
    "\n",
    "        # Get the hyperlinks from the URL and add them to the queue\n",
    "        for link in get_domain_hyperlinks(local_domain, url):\n",
    "            if link not in seen:\n",
    "                queue.append(link)\n",
    "                seen.add(link)\n",
    "\n",
    "crawl(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.str.replace('\\n', ' ')\n",
    "    serie = serie.str.replace('\\\\n', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grant_64eiczj\\AppData\\Local\\Temp\\ipykernel_15372\\2931785837.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  serie = serie.str.replace('\\\\n', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fname text\n",
       "0         . "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the text files\n",
    "texts=[]\n",
    "\n",
    "# Get all the text files in the text directory\n",
    "for file in os.listdir(\"text/\" + domain + \"/\"):\n",
    "\n",
    "    # Open the file and read the text\n",
    "    with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Omit the first 11 lines and the last 4 lines, then replace -, _, and #update with spaces.\n",
    "        texts.append((file[11:-4].replace('-',' ').replace('_', ' ').replace('#update',''), text))\n",
    "\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(texts, columns = ['fname', 'text'])\n",
    "\n",
    "# Set the text column to be the raw text with the newlines removed\n",
    "df['text'] = df.fname + \". \" + remove_newlines(df.text)\n",
    "df.to_csv('processed/scraped.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the cl100k_base tokenizer which is designed to work with the ada-002 model\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "df = pd.read_csv('processed/scraped.csv', index_col=0)\n",
    "df.columns = ['title', 'text']\n",
    "\n",
    "# Tokenize the text and save the number of tokens to a new column\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "# Visualize the distribution of the number of tokens per row using a histogram\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 500\n",
    "\n",
    "# Function to split the text into chunks of a maximum number of tokens\n",
    "def split_into_many(text, max_tokens = max_tokens):\n",
    "\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split('. ')\n",
    "\n",
    "    # Get the number of tokens for each sentence\n",
    "    n_tokens = [len(tokenizer.encode(\" \" + sentence)) for sentence in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    tokens_so_far = 0\n",
    "    chunk = []\n",
    "\n",
    "    # Loop through the sentences and tokens joined together in a tuple\n",
    "    for sentence, token in zip(sentences, n_tokens):\n",
    "\n",
    "        # If the number of tokens so far plus the number of tokens in the current sentence is greater \n",
    "        # than the max number of tokens, then add the chunk to the list of chunks and reset\n",
    "        # the chunk and tokens so far\n",
    "        if tokens_so_far + token > max_tokens:\n",
    "            chunks.append(\". \".join(chunk) + \".\")\n",
    "            chunk = []\n",
    "            tokens_so_far = 0\n",
    "\n",
    "        # If the number of tokens in the current sentence is greater than the max number of \n",
    "        # tokens, go to the next sentence\n",
    "        if token > max_tokens:\n",
    "            continue\n",
    "\n",
    "        # Otherwise, add the sentence to the chunk and add the number of tokens to the total\n",
    "        chunk.append(sentence)\n",
    "        tokens_so_far += token + 1\n",
    "\n",
    "    return chunks\n",
    "    \n",
    "\n",
    "shortened = []\n",
    "\n",
    "# Loop through the dataframe\n",
    "for row in df.iterrows():\n",
    "\n",
    "    # If the text is None, go to the next row\n",
    "    if row[1]['text'] is None:\n",
    "        continue\n",
    "\n",
    "    # If the number of tokens is greater than the max number of tokens, split the text into chunks\n",
    "    if row[1]['n_tokens'] > max_tokens:\n",
    "        shortened += split_into_many(row[1]['text'])\n",
    "    \n",
    "    # Otherwise, add the text to the list of shortened texts\n",
    "    else:\n",
    "        shortened.append( row[1]['text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(shortened, columns = ['text'])\n",
    "df['n_tokens'] = df.text.apply(lambda x: len(tokenizer.encode(x)))\n",
    "df.n_tokens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mx, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtext-embedding-ada-002\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      4\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mprocessed/embeddings.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[30], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mx, engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtext-embedding-ada-002\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mprocessed/embeddings.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[0;32m    107\u001b[0m     api_key,\n\u001b[0;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[0;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[0;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    115\u001b[0m     deployment_id,\n\u001b[0;32m    116\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m     params,\n\u001b[0;32m    125\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\openai\\api_requestor.py:130\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m ):\n\u001b[0;32m    129\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[1;32m--> 130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[0;32m    131\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[0;32m    132\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    133\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[0;32m    134\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[1;32mc:\\Users\\grant_64eiczj\\source\\repos\\openai-cookbook\\env\\Lib\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "df.to_csv('processed/embeddings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog authors maddie.   Maddie Hall - OpenAI   ...</td>\n",
       "      <td>175</td>\n",
       "      <td>[-0.012958061881363392, -0.006103983614593744,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog authors tom.   Tom Brown - OpenAI        ...</td>\n",
       "      <td>228</td>\n",
       "      <td>[-0.0053874170407652855, -0.009962032549083233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog openai scholars 2019 final projects.   Op...</td>\n",
       "      <td>492</td>\n",
       "      <td>[0.0019150723237544298, -0.0070442273281514645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this project, I used curiosity-driven explo...</td>\n",
       "      <td>478</td>\n",
       "      <td>[-0.0067560747265815735, 0.0004431474662851542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Results revealed that the optimal RL policies ...</td>\n",
       "      <td>499</td>\n",
       "      <td>[-0.012868616729974747, 0.0029640409629791975,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_tokens  \\\n",
       "0  blog authors maddie.   Maddie Hall - OpenAI   ...       175   \n",
       "1  blog authors tom.   Tom Brown - OpenAI        ...       228   \n",
       "2  blog openai scholars 2019 final projects.   Op...       492   \n",
       "3  In this project, I used curiosity-driven explo...       478   \n",
       "4  Results revealed that the optimal RL policies ...       499   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.012958061881363392, -0.006103983614593744,...  \n",
       "1  [-0.0053874170407652855, -0.009962032549083233...  \n",
       "2  [0.0019150723237544298, -0.0070442273281514645...  \n",
       "3  [-0.0067560747265815735, 0.0004431474662851542...  \n",
       "4  [-0.012868616729974747, 0.0029640409629791975,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.embeddings_utils import distances_from_embeddings\n",
    "\n",
    "df['embeddings'] = df.text.apply(lambda x: openai.Embedding.create(input=x, engine='text-embedding-ada-002')['data'][0]['embedding'])\n",
    "\n",
    "df.to_csv('processed/embeddings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog authors maddie.   Maddie Hall - OpenAI   ...</td>\n",
       "      <td>175</td>\n",
       "      <td>[-0.012958061881363392, -0.006103983614593744,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog authors tom.   Tom Brown - OpenAI        ...</td>\n",
       "      <td>228</td>\n",
       "      <td>[-0.0053874170407652855, -0.009962032549083233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog openai scholars 2019 final projects.   Op...</td>\n",
       "      <td>492</td>\n",
       "      <td>[0.0019150723237544298, -0.0070442273281514645...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this project, I used curiosity-driven explo...</td>\n",
       "      <td>478</td>\n",
       "      <td>[-0.0067560747265815735, 0.0004431474662851542...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Results revealed that the optimal RL policies ...</td>\n",
       "      <td>499</td>\n",
       "      <td>[-0.012868616729974747, 0.0029640409629791975,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_tokens  \\\n",
       "0  blog authors maddie.   Maddie Hall - OpenAI   ...       175   \n",
       "1  blog authors tom.   Tom Brown - OpenAI        ...       228   \n",
       "2  blog openai scholars 2019 final projects.   Op...       492   \n",
       "3  In this project, I used curiosity-driven explo...       478   \n",
       "4  Results revealed that the optimal RL policies ...       499   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.012958061881363392, -0.006103983614593744,...  \n",
       "1  [-0.0053874170407652855, -0.009962032549083233...  \n",
       "2  [0.0019150723237544298, -0.0070442273281514645...  \n",
       "3  [-0.0067560747265815735, 0.0004431474662851542...  \n",
       "4  [-0.012868616729974747, 0.0029640409629791975,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import distances_from_embeddings, cosine_similarity\n",
    "\n",
    "df=pd.read_csv('processed/embeddings.csv', index_col=0)\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, you are not allowed to publish model outputs to Twitter without a human review. You must manually review each generation before sharing or while streaming, and indicate that the content is AI-generated in a way no user could reasonably miss or misunderstand.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_context(\n",
    "    question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "\n",
    "    # Get the distances from the embeddings\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "\n",
    "\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "        \n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "        \n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "        \n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)\n",
    "\n",
    "def answer_question(\n",
    "    df,\n",
    "    model=\"text-davinci-003\",\n",
    "    question=\"Am I allowed to publish model outputs to Twitter, without a human review?\",\n",
    "    max_len=1800,\n",
    "    size=\"ada\",\n",
    "    debug=False,\n",
    "    max_tokens=150,\n",
    "    stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the question and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer_question(df, question=\"What day is it?\", debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The newest embeddings model is text-embedding-ada-002.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(df, question=\"What is our newest embeddings model?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f199e9c60d5a3acbfc2d1fa3313266664aa68cc5c548e4565762cc393078176"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
